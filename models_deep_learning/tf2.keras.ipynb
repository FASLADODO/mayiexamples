{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.keras概览\n",
    "https://tensorflow.google.cn/api_docs/python/tf/keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a simple model--Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "# Adds a densely-connected layer with 64 units to the model:\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# Add another:\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# Add a softmax layer with 10 output units:\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the layers\n",
    "* activation: Set the activation function for the layer. This parameter is specified by the name of a built-in function or as a callable object. By default, no activation is applied.\n",
    "* kernel_initializer and bias_initializer: The initialization schemes that create the layer's weights (kernel and bias). This parameter is a name or a callable object. This defaults to the \"Glorot uniform\" initializer.\n",
    "* kernel_regularizer and bias_regularizer: The regularization schemes that apply the layer's weights (kernel and bias), such as L1 or L2 regularization. By default, no regularization is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x13b78cf60>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sigmoid layer:\n",
    "layers.Dense(64, activation='sigmoid')\n",
    "# Or:\n",
    "layers.Dense(64, activation=tf.keras.activations.sigmoid)\n",
    "\n",
    "# A linear layer with L1 regularization of factor 0.01 applied to the kernel matrix:\n",
    "layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l1(0.01))\n",
    "\n",
    "# A linear layer with L2 regularization of factor 0.01 applied to the bias vector:\n",
    "layers.Dense(64, bias_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "\n",
    "# A linear layer with a kernel initialized to a random orthogonal matrix:\n",
    "layers.Dense(64, kernel_initializer='orthogonal')\n",
    "\n",
    "# A linear layer with a bias vector initialized to 2.0s:\n",
    "layers.Dense(64, bias_initializer=tf.keras.initializers.Constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "# Adds a densely-connected layer with 64 units to the model:\n",
    "layers.Dense(64, activation='relu', input_shape=(32,)),\n",
    "# Add another:\n",
    "layers.Dense(64, activation='relu'),\n",
    "# Add a softmax layer with 10 output units:\n",
    "layers.Dense(10, activation='softmax')])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.keras.Model.compile takes three important arguments:\n",
    "\n",
    "* optimizer: This object specifies the training procedure. Pass it optimizer instances from the tf.keras.optimizers module, such as tf.keras.optimizers.Adam or tf.keras.optimizers.SGD. If you just want to use the default parameters, you can also specify optimizers via strings, such as 'adam' or 'sgd'.\n",
    "* loss: The function to minimize during optimization. Common choices include mean square error (mse), categorical_crossentropy, and binary_crossentropy. Loss functions are specified by name or by passing a callable object from the tf.keras.losses module.\n",
    "* metrics: Used to monitor training. These are string names or callables from the tf.keras.metrics module.\n",
    "* Additionally, to make sure the model trains and evaluates eagerly, you can make sure to pass run_eagerly=True as a parameter to compile.\n",
    "\n",
    "The following shows a few examples of configuring a model for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure a model for mean-squared error regression.\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "              loss='mse',       # mean squared error\n",
    "              metrics=['mae'])  # mean absolute error\n",
    "\n",
    "# Configure a model for categorical classification.\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.01),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train from NumPy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 660us/sample - loss: 25.7322 - accuracy: 0.1130\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 208.8320 - accuracy: 0.1120\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 929.5049 - accuracy: 0.1030\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 1703.7768 - accuracy: 0.0990\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 4012.0033 - accuracy: 0.1060\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 7791.5488 - accuracy: 0.1070\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 11280.8306 - accuracy: 0.0840\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 20020.8224 - accuracy: 0.0890\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 19549.7783 - accuracy: 0.1080\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 28377.9478 - accuracy: 0.0920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x141091c18>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "model.fit(data, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example using validation_data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 148us/sample - loss: 40965.3121 - accuracy: 0.1060 - val_loss: 54195.8666 - val_accuracy: 0.0400\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 81us/sample - loss: 49548.4699 - accuracy: 0.1050 - val_loss: 41730.7855 - val_accuracy: 0.1300\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 88us/sample - loss: 50720.4791 - accuracy: 0.1000 - val_loss: 55317.3403 - val_accuracy: 0.0800\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 63645.3235 - accuracy: 0.1080 - val_loss: 74619.0509 - val_accuracy: 0.1300\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 81001.9045 - accuracy: 0.0970 - val_loss: 105868.2666 - val_accuracy: 0.0800\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 62us/sample - loss: 114409.0335 - accuracy: 0.1130 - val_loss: 164796.9225 - val_accuracy: 0.0800\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 78us/sample - loss: 99691.5519 - accuracy: 0.0980 - val_loss: 104956.7047 - val_accuracy: 0.1200\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 98029.7159 - accuracy: 0.1010 - val_loss: 91877.7875 - val_accuracy: 0.0800\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 106469.4140 - accuracy: 0.1000 - val_loss: 132864.9634 - val_accuracy: 0.0900\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 77us/sample - loss: 149190.3763 - accuracy: 0.1020 - val_loss: 155763.7838 - val_accuracy: 0.1100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14328e7b8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "val_data = np.random.random((100, 32))\n",
    "val_labels = np.random.random((100, 10))\n",
    "\n",
    "model.fit(data, labels, epochs=10, batch_size=32,\n",
    "          validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train from tf.data datasets\n",
    "Use the Datasets API to scale to large datasets or multi-device training. Pass a tf.data.Dataset instance to the fit method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 123703.0825 - accuracy: 0.1030\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 106241.4956 - accuracy: 0.0990\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 173562.8943 - accuracy: 0.0930\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 205254.7680 - accuracy: 0.0890\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 177919.0564 - accuracy: 0.1170\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 223075.0376 - accuracy: 0.0850\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 177457.0407 - accuracy: 0.0950\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 167000.0721 - accuracy: 0.1030\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 189559.0902 - accuracy: 0.0840\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 250667.4692 - accuracy: 0.0990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1431b1208>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiates a toy dataset instance:\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(32)\n",
    "\n",
    "model.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets can also be used for validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 359380.5967 - accuracy: 0.0990 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 345115.9201 - accuracy: 0.1040 - val_loss: 156944.9336 - val_accuracy: 0.1200\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 225164.5492 - accuracy: 0.0950 - val_loss: 389806.0781 - val_accuracy: 0.1600\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 303205.6797 - accuracy: 0.1120 - val_loss: 209036.5039 - val_accuracy: 0.0800\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 294900.3774 - accuracy: 0.0900 - val_loss: 265484.1953 - val_accuracy: 0.0700\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 351249.5470 - accuracy: 0.1050 - val_loss: 380213.3672 - val_accuracy: 0.0800\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 402041.9904 - accuracy: 0.0950 - val_loss: 461212.1875 - val_accuracy: 0.1600\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 435980.2455 - accuracy: 0.0960 - val_loss: 463340.9688 - val_accuracy: 0.1100\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 536288.1982 - accuracy: 0.1000 - val_loss: 787362.7656 - val_accuracy: 0.0800\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 548587.6743 - accuracy: 0.0920 - val_loss: 579733.6562 - val_accuracy: 0.1200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1433a6748>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(32)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "\n",
    "model.fit(dataset, epochs=10,\n",
    "          validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1000/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 28us/sample - loss: 572720.9800 - accuracy: 0.0920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[572681.335, 0.092]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With Numpy arrays\n",
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "model.evaluate(data, labels, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 958us/step - loss: 572683.1934 - accuracy: 0.0920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[572683.193359375, 0.092]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With a Dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(32)\n",
    "\n",
    "model.evaluate(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(data, batch_size=32)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build complex models--The Functional API\n",
    "The tf.keras.Sequential model is a simple stack of layers that cannot represent arbitrary models. Use the Keras functional API to build complex model topologies such as:\n",
    "\n",
    "* Multi-input models,\n",
    "* Multi-output models,\n",
    "* Models with shared layers (the same layer called several times),\n",
    "* Models with non-sequential data flows (e.g. residual connections).\n",
    "\n",
    "Building a model with the functional API works like this:\n",
    "\n",
    "1. A layer instance is callable and returns a tensor.\n",
    "1. Input tensors and output tensors are used to define a tf.keras.Model instance.\n",
    "1. This model is trained just like the Sequential model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(32,))  # Returns an input placeholder\n",
    "\n",
    "# A layer instance is callable on a tensor, and returns a tensor.\n",
    "x = layers.Dense(64, activation='relu')(inputs)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "predictions = layers.Dense(10, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 1s 501us/sample - loss: 13.6575 - accuracy: 0.0960\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 22.3767 - accuracy: 0.0920\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 35.9141 - accuracy: 0.0860\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 52.3935 - accuracy: 0.1030\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 72.4794 - accuracy: 0.1010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1439b21d0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# The compile step specifies the training configuration.\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Trains for 5 epochs\n",
    "model.fit(data, labels, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model subclassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, num_classes=10):\n",
    "    super(MyModel, self).__init__(name='my_model')\n",
    "    self.num_classes = num_classes\n",
    "    # Define your layers here.\n",
    "    self.dense_1 = layers.Dense(32, activation='relu')\n",
    "    self.dense_2 = layers.Dense(num_classes, activation='sigmoid')\n",
    "\n",
    "  def call(self, inputs):\n",
    "    # Define your forward pass here,\n",
    "    # using layers you previously defined (in `__init__`).\n",
    "    x = self.dense_1(inputs)\n",
    "    return self.dense_2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 11.4251 - accuracy: 0.0890\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 11.4008 - accuracy: 0.1030\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 11.3957 - accuracy: 0.1120\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 11.3928 - accuracy: 0.1060\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 11.3915 - accuracy: 0.1100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x144096fd0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the new model class:\n",
    "model = MyModel(num_classes=10)\n",
    "\n",
    "# The compile step specifies the training configuration.\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Trains for 5 epochs.\n",
    "model.fit(data, labels, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom layers\n",
    "Create a custom layer by subclassing tf.keras.layers.Layer and implementing the following methods:\n",
    "\n",
    "* `__init__`: Optionally define sublayers to be used by this layer.\n",
    "* build: Create the weights of the layer. Add weights with the add_weight method.\n",
    "* call: Define the forward pass.\n",
    "* Optionally, a layer can be serialized by implementing the get_config method and the from_config class method.\n",
    "\n",
    "Here's an example of a custom layer that implements a matmul of an input with a kernel matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLayer(layers.Layer):\n",
    "\n",
    "  def __init__(self, output_dim, **kwargs):\n",
    "    self.output_dim = output_dim\n",
    "    super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    # Create a trainable weight variable for this layer.\n",
    "    self.kernel = self.add_weight(name='kernel',\n",
    "                                  shape=(input_shape[1], self.output_dim),\n",
    "                                  initializer='uniform',\n",
    "                                  trainable=True)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return tf.matmul(inputs, self.kernel)\n",
    "\n",
    "  def get_config(self):\n",
    "    base_config = super(MyLayer, self).get_config()\n",
    "    base_config['output_dim'] = self.output_dim\n",
    "    return base_config\n",
    "\n",
    "  @classmethod\n",
    "  def from_config(cls, config):\n",
    "    return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 292us/sample - loss: 11.4139 - accuracy: 0.1060\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 11.4144 - accuracy: 0.1070\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 11.4143 - accuracy: 0.1070\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 11.4145 - accuracy: 0.1080\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 11.4137 - accuracy: 0.1070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14396bcc0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a model using your custom layer:\n",
    "model = tf.keras.Sequential([\n",
    "    MyLayer(10),\n",
    "    layers.Activation('softmax')])\n",
    "\n",
    "# The compile step specifies the training configuration\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Trains for 5 epochs.\n",
    "model.fit(data, labels, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks\n",
    "A callback is an object passed to a model to customize and extend its behavior during training. You can write your own custom callback, or use the built-in tf.keras.callbacks that include:\n",
    "\n",
    "* tf.keras.callbacks.ModelCheckpoint: Save checkpoints of your model at regular intervals.\n",
    "* tf.keras.callbacks.LearningRateScheduler: Dynamically change the learning rate.\n",
    "* tf.keras.callbacks.EarlyStopping: Interrupt training when validation performance has stopped improving.\n",
    "* tf.keras.callbacks.TensorBoard: Monitor the model's behavior using TensorBoard.\n",
    "\n",
    "To use a tf.keras.callbacks.Callback, pass it to the model's fit method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 222us/sample - loss: 11.4132 - accuracy: 0.1030 - val_loss: 11.7068 - val_accuracy: 0.0600\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 11.4137 - accuracy: 0.1030 - val_loss: 11.7069 - val_accuracy: 0.0700\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 11.4131 - accuracy: 0.1020 - val_loss: 11.7064 - val_accuracy: 0.0700\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 84us/sample - loss: 11.4126 - accuracy: 0.1040 - val_loss: 11.7056 - val_accuracy: 0.0700\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 66us/sample - loss: 11.4123 - accuracy: 0.1030 - val_loss: 11.7061 - val_accuracy: 0.0700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1449e64a8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [\n",
    "  # Interrupt training if `val_loss` stops improving for over 2 epochs\n",
    "  tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),\n",
    "  # Write TensorBoard logs to `./logs` directory\n",
    "  tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "]\n",
    "model.fit(data, labels, batch_size=32, epochs=5, callbacks=callbacks,\n",
    "          validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and restore\n",
    "\n",
    "### Save just the weights values\n",
    "Save and load the weights of a model using tf.keras.Model.save_weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "layers.Dense(64, activation='relu', input_shape=(32,)),\n",
    "layers.Dense(10, activation='softmax')])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x144b23048>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save weights to a TensorFlow Checkpoint file\n",
    "model.save_weights('./weights/my_model')\n",
    "\n",
    "# Restore the model's state,\n",
    "# this requires a model with the same architecture.\n",
    "model.load_weights('./weights/my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, this saves the model's weights in the TensorFlow checkpoint file format. Weights can also be saved to the Keras HDF5 format (the default for the multi-backend implementation of Keras):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights to a HDF5 file\n",
    "model.save_weights('my_model.h5', save_format='h5')\n",
    "\n",
    "# Restore the model's state\n",
    "model.load_weights('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save just the model configuration\n",
    "A model's configuration can be saved—this serializes the model architecture without any weights. A saved configuration can recreate and initialize the same model, even without the code that defined the original model. Keras supports JSON and YAML serialization formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_3\", \"layers\": [{\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_17\", \"trainable\": true, \"batch_input_shape\": [null, 32], \"dtype\": \"float32\", \"units\": 64, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_18\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 10, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.2.4-tf\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Serialize a model to JSON format\n",
    "json_string = model.to_json()\n",
    "json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'backend': 'tensorflow',\n",
      " 'class_name': 'Sequential',\n",
      " 'config': {'layers': [{'class_name': 'Dense',\n",
      "                        'config': {'activation': 'relu',\n",
      "                                   'activity_regularizer': None,\n",
      "                                   'batch_input_shape': [None, 32],\n",
      "                                   'bias_constraint': None,\n",
      "                                   'bias_initializer': {'class_name': 'Zeros',\n",
      "                                                        'config': {}},\n",
      "                                   'bias_regularizer': None,\n",
      "                                   'dtype': 'float32',\n",
      "                                   'kernel_constraint': None,\n",
      "                                   'kernel_initializer': {'class_name': 'GlorotUniform',\n",
      "                                                          'config': {'seed': None}},\n",
      "                                   'kernel_regularizer': None,\n",
      "                                   'name': 'dense_17',\n",
      "                                   'trainable': True,\n",
      "                                   'units': 64,\n",
      "                                   'use_bias': True}},\n",
      "                       {'class_name': 'Dense',\n",
      "                        'config': {'activation': 'softmax',\n",
      "                                   'activity_regularizer': None,\n",
      "                                   'bias_constraint': None,\n",
      "                                   'bias_initializer': {'class_name': 'Zeros',\n",
      "                                                        'config': {}},\n",
      "                                   'bias_regularizer': None,\n",
      "                                   'dtype': 'float32',\n",
      "                                   'kernel_constraint': None,\n",
      "                                   'kernel_initializer': {'class_name': 'GlorotUniform',\n",
      "                                                          'config': {'seed': None}},\n",
      "                                   'kernel_regularizer': None,\n",
      "                                   'name': 'dense_18',\n",
      "                                   'trainable': True,\n",
      "                                   'units': 10,\n",
      "                                   'use_bias': True}}],\n",
      "            'name': 'sequential_3'},\n",
      " 'keras_version': '2.2.4-tf'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pprint\n",
    "pprint.pprint(json.loads(json_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recreate the model (newly initialized) from the JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "fresh_model = tf.keras.models.model_from_json(json_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serializing a model to YAML format requires that you install pyyaml before you import TensorFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backend: tensorflow\n",
      "class_name: Sequential\n",
      "config:\n",
      "  layers:\n",
      "  - class_name: Dense\n",
      "    config:\n",
      "      activation: relu\n",
      "      activity_regularizer: null\n",
      "      batch_input_shape: !!python/tuple\n",
      "      - null\n",
      "      - 32\n",
      "      bias_constraint: null\n",
      "      bias_initializer:\n",
      "        class_name: Zeros\n",
      "        config: {}\n",
      "      bias_regularizer: null\n",
      "      dtype: float32\n",
      "      kernel_constraint: null\n",
      "      kernel_initializer:\n",
      "        class_name: GlorotUniform\n",
      "        config:\n",
      "          seed: null\n",
      "      kernel_regularizer: null\n",
      "      name: dense_17\n",
      "      trainable: true\n",
      "      units: 64\n",
      "      use_bias: true\n",
      "  - class_name: Dense\n",
      "    config:\n",
      "      activation: softmax\n",
      "      activity_regularizer: null\n",
      "      bias_constraint: null\n",
      "      bias_initializer:\n",
      "        class_name: Zeros\n",
      "        config: {}\n",
      "      bias_regularizer: null\n",
      "      dtype: float32\n",
      "      kernel_constraint: null\n",
      "      kernel_initializer:\n",
      "        class_name: GlorotUniform\n",
      "        config:\n",
      "          seed: null\n",
      "      kernel_regularizer: null\n",
      "      name: dense_18\n",
      "      trainable: true\n",
      "      units: 10\n",
      "      use_bias: true\n",
      "  name: sequential_3\n",
      "keras_version: 2.2.4-tf\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yaml_string = model.to_yaml()\n",
    "print(yaml_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recreate the model from the YAML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luoyonggui/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/model_config.py:76: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  config = yaml.load(yaml_string)\n"
     ]
    }
   ],
   "source": [
    "fresh_model = tf.keras.models.model_from_yaml(yaml_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the entire model in one file\n",
    "The entire model can be saved to a file that contains the weight values, the model's configuration, and even the optimizer's configuration. This allows you to checkpoint a model and resume training later—from the exact same state—without access to the original code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 388us/sample - loss: 11.4263 - accuracy: 0.0950\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 11.4285 - accuracy: 0.1070\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 11.4420 - accuracy: 0.1010\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 11.4604 - accuracy: 0.1000\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 11.4786 - accuracy: 0.0970\n"
     ]
    }
   ],
   "source": [
    "# Create a simple model\n",
    "model = tf.keras.Sequential([\n",
    "  layers.Dense(10, activation='softmax', input_shape=(32,)),\n",
    "  layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(data, labels, batch_size=32, epochs=5)\n",
    "\n",
    "\n",
    "# Save entire model to a HDF5 file\n",
    "model.save('my_model.h5')\n",
    "\n",
    "# Recreate the exact same model, including weights and optimizer.\n",
    "model = tf.keras.models.load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks (RNN) with Keras\n",
    "https://tensorflow.google.cn/guide/keras/rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a simple model\n",
    "There are three built-in RNN layers in Keras:\n",
    "\n",
    "* tf.keras.layers.SimpleRNN, a fully-connected RNN where the output from previous timestep is to be fed to next timestep.\n",
    "\n",
    "* tf.keras.layers.GRU, first proposed in Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation.\n",
    "\n",
    "* tf.keras.layers.LSTM, first proposed in Long Short-Term Memory.\n",
    "\n",
    "In early 2015, Keras had the first reusable open-source Python implementations of LSTM and GRU.\n",
    "\n",
    "Here is a simple example of a Sequential model that processes sequences of integers, embeds each integer into a 64-dimensional vector, then processes the sequence of vectors using a LSTM layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          64000     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 164,106\n",
      "Trainable params: 164,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "# Add an Embedding layer expecting input vocab of size 1000, and\n",
    "# output embedding dimension of size 64.\n",
    "model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
    "\n",
    "# Add a LSTM layer with 128 internal units.\n",
    "model.add(layers.LSTM(128))\n",
    "\n",
    "# Add a Dense layer with 10 units and softmax activation.\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputs and states\n",
    "By default, the output of a RNN layer contain a single vector per sample. This vector is the RNN cell output corresponding to the last timestep, containing information about the entire input sequence. The shape of this output is **(batch_size, units)** where units corresponds to the units argument passed to the layer's constructor.\n",
    "\n",
    "A RNN layer can also return the entire sequence of outputs for each sample (one vector per timestep per sample), if you set `return_sequences=True`. The shape of this output is **(batch_size, timesteps, units)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 64)          64000     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, None, 256)         247296    \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 128)               49280     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 361,866\n",
      "Trainable params: 361,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
    "\n",
    "# The output of GRU will be a 3D tensor of shape (batch_size, timesteps, 256)\n",
    "model.add(layers.GRU(256, return_sequences=True))\n",
    "\n",
    "# The output of SimpleRNN will be a 2D tensor of shape (batch_size, 128)\n",
    "model.add(layers.SimpleRNN(128))\n",
    "\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encoder-decoder sequence-to-sequence model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, a RNN layer can return its final internal state(s). The returned states can be used to resume the RNN execution later, or to initialize another RNN. This setting is commonly used in the encoder-decoder sequence-to-sequence model, where the encoder final state is used as the initial state of the decoder.\n",
    "\n",
    "To configure a RNN layer to return its internal state, set the return_state parameter to True when creating the layer. **Note that LSTM has 2 state tensors, but GRU only has one**.\n",
    "\n",
    "To configure the initial state of the layer, just call the layer with additional keyword argument initial_state. Note that the shape of the state needs to match the unit size of the layer, like in the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 64)     64000       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 64)     128000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "encoder (LSTM)                  [(None, 64), (None,  33024       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder (LSTM)                  (None, 64)           33024       embedding_3[0][0]                \n",
      "                                                                 encoder[0][1]                    \n",
      "                                                                 encoder[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           650         decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 258,698\n",
      "Trainable params: 258,698\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_vocab = 1000\n",
    "decoder_vocab = 2000\n",
    "\n",
    "encoder_input = layers.Input(shape=(None, ))\n",
    "encoder_embedded = layers.Embedding(input_dim=encoder_vocab, output_dim=64)(encoder_input)\n",
    "\n",
    "# Return states in addition to output\n",
    "output, state_h, state_c = layers.LSTM(\n",
    "    64, return_state=True, name='encoder')(encoder_embedded)\n",
    "encoder_state = [state_h, state_c]\n",
    "\n",
    "decoder_input = layers.Input(shape=(None, ))\n",
    "decoder_embedded = layers.Embedding(input_dim=decoder_vocab, output_dim=64)(decoder_input)\n",
    "\n",
    "# Pass the 2 states to a new LSTM layer, as initial state\n",
    "decoder_output = layers.LSTM(\n",
    "    64, name='decoder')(decoder_embedded, initial_state=encoder_state)\n",
    "output = layers.Dense(10, activation='softmax')(decoder_output)\n",
    "\n",
    "model = tf.keras.Model([encoder_input, decoder_input], output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional RNNs\n",
    "For sequences other than time series (e.g. text), it is often the case that a RNN model can perform better if it not only processes sequence from start to end, but also backwards. For example, to predict the next word in a sentence, it is often useful to have the context around the word, not only just the words that come before it.\n",
    "\n",
    "Keras provides an easy API for you to build such bidirectional RNNs: the tf.keras.layers.Bidirectional wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional (Bidirectional (None, 5, 128)            38400     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 64)                41216     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 80,266\n",
      "Trainable params: 80,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(layers.Bidirectional(layers.LSTM(64, return_sequences=True), \n",
    "                               input_shape=(5, 10)))\n",
    "model.add(layers.Bidirectional(layers.LSTM(32)))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masking and padding with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding sequence data\n",
    "When processing sequence data, it is very common for individual samples to have different lengths. Consider the following example (text tokenized as words):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'weather', 'will', 'be', 'nice', 'tomorrow'],\n",
       " ['How', 'are', 'you', 'doing', 'today'],\n",
       " ['Hello', 'world', '!']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "  [\"The\", \"weather\", \"will\", \"be\", \"nice\", \"tomorrow\"],\n",
    "  [\"How\", \"are\", \"you\", \"doing\", \"today\"],\n",
    "  [\"Hello\", \"world\", \"!\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After vocabulary lookup, the data might be vectorized as integers, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[83, 91, 1, 645, 1253, 927], [73, 8, 3215, 55, 927], [71, 1331, 4231]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "  [83, 91, 1, 645, 1253, 927],\n",
    "  [73, 8, 3215, 55, 927],\n",
    "  [71, 1331, 4231]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  83   91    1  645 1253  927]\n",
      " [  73    8 3215   55  927    0]\n",
      " [ 711  632   71    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = [\n",
    "  [83, 91, 1, 645, 1253, 927],\n",
    "  [73, 8, 3215, 55, 927],\n",
    "  [711, 632, 71]\n",
    "]\n",
    "\n",
    "# By default, this will pad using 0s; it is configurable via the\n",
    "# \"value\" parameter.\n",
    "# Note that you could \"pre\" padding (at the beginning) or\n",
    "# \"post\" padding (at the end).\n",
    "# We recommend using \"post\" padding when working with RNN layers\n",
    "# (in order to be able to use the \n",
    "# CuDNN implementation of the layers).\n",
    "padded_inputs = tf.keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                              padding='post')\n",
    "\n",
    "print(padded_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking\n",
    "Now that all samples have a uniform length, the model must be informed that some part of the data is actually padding and should be ignored. That mechanism is masking.\n",
    "\n",
    "There are three ways to introduce input masks in Keras models:\n",
    "\n",
    "* Add a `keras.layers.Masking` layer.\n",
    "* Configure a `keras.layers.Embedding` layer with `mask_zero=True`.\n",
    "* Pass a mask argument manually when calling layers that support this argument (e.g. RNN layers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask-generating layers: Embedding and Masking\n",
    "Under the hood, these layers will create a mask tensor (2D tensor with shape (batch, sequence_length)), and attach it to the tensor output returned by the Masking or Embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ True  True  True  True  True  True]\n",
      " [ True  True  True  True  True False]\n",
      " [ True  True  True False False False]], shape=(3, 6), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "embedding = layers.Embedding(input_dim=5000, output_dim=16, mask_zero=True)\n",
    "masked_output = embedding(padded_inputs)\n",
    "\n",
    "print(masked_output._keras_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ True  True  True  True  True  True]\n",
      " [ True  True  True  True  True False]\n",
      " [ True  True  True False False False]], shape=(3, 6), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "masking_layer = layers.Masking()\n",
    "# Simulate the embedding lookup by expanding the 2D input to 3D,\n",
    "# with embedding dimension of 10.\n",
    "unmasked_embedding = tf.cast(\n",
    "    tf.tile(tf.expand_dims(padded_inputs, axis=-1), [1, 1, 10]),\n",
    "    tf.float32)\n",
    "\n",
    "masked_embedding = masking_layer(unmasked_embedding)\n",
    "print(masked_embedding._keras_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask propagation(传播) in the Functional API and Sequential API\n",
    "When using the Functional API or the Sequential API, a mask generated by an Embedding or Masking layer will be propagated through the network for any layer that is capable of using them (for example, RNN layers). Keras will automatically fetch the mask corresponding to an input and pass it to any layer that knows how to use it.\n",
    "\n",
    "Note that in the call method of a subclassed model or layer, masks aren't automatically propagated, so you will need to manually pass a mask argument to any layer that needs one. See the section below for details.\n",
    "\n",
    "For instance, in the following Sequential model, the LSTM layer will automatically receive a mask, which means it will ignore padded values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embeddings\n",
    "## Representing text as numbers\n",
    "* One-hot encodings\n",
    "* Encode each word with a unique number\n",
    "* Word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow-datasets==1.3.0\r\n"
     ]
    }
   ],
   "source": [
    "# !pip install tensorflow_datasets\n",
    "!pip freeze | grep tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "tfds.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Embedding layer\n",
    "Keras makes it easy to use word embeddings. Let's take a look at the Embedding layer.\n",
    "\n",
    "The Embedding layer can be understood as a lookup table that maps from integer indices (which stand for specific words) to dense vectors (their embeddings). The dimensionality (or width) of the embedding is a parameter you can experiment with to see what works well for your problem, much in the same way you would experiment with the number of neurons in a Dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = layers.Embedding(1000, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you create an Embedding layer, the weights for the embedding are randomly initialized (just like any other layer). During training, they are gradually adjusted via backpropagation. Once trained, the learned word embeddings will roughly encode similarities between words (as they were learned for the specific problem your model is trained on).\n",
    "\n",
    "If you pass an integer to an embedding layer, the result replaces each integer with the vector from the embedding table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=4543, shape=(3, 5), dtype=float32, numpy=\n",
       "array([[ 0.00241987, -0.01758017, -0.01845681,  0.0114537 ,  0.03800228],\n",
       "       [ 0.043493  ,  0.0058952 , -0.00655357,  0.04754883, -0.03791286],\n",
       "       [ 0.03135024,  0.01157562, -0.01283092, -0.0042626 , -0.01847968]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = embedding_layer(tf.constant([1,2,3]))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00241987, -0.01758017, -0.01845681,  0.0114537 ,  0.03800228],\n",
       "       [ 0.043493  ,  0.0058952 , -0.00655357,  0.04754883, -0.03791286],\n",
       "       [ 0.03135024,  0.01157562, -0.01283092, -0.0042626 , -0.01847968]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3, 5])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = embedding_layer(tf.constant([[0,1,2],[3,4,5]]))\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
